{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_federated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_federated\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtff\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, layers\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_federated'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV file and image data\n",
    "def load_data_from_csv_and_images(csv_file, image_folder, image_size=(224, 224)):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Prepare image paths and labels\n",
    "    image_paths = [os.path.join(image_folder, fname) for fname in df['filename']]\n",
    "    labels = df['label'].values\n",
    "    \n",
    "    # Load and resize images\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = image.load_img(img_path, target_size=image_size)\n",
    "        img_array = image.img_to_array(img) / 255.0  # Rescale the image\n",
    "        images.append(img_array)\n",
    "    \n",
    "    # Convert images and labels to numpy arrays\n",
    "    images = np.array(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Step 2: Local Model Creation Using ResNet-101\n",
    "def create_model(num_classes):\n",
    "   \n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # Freeze the base model layers\n",
    "    \n",
    "    # Define custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model, \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train Local Model\n",
    "def train_local_model(train_images, train_labels, val_images, val_labels, model, epochs=10, batch_size=32):\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Federated Learning Setup (Using TensorFlow Federated)\n",
    "def model_fn():\n",
    "    num_classes = 3  # Adjust based on your number of classes\n",
    "    model = create_model(num_classes)\n",
    "    \n",
    "    # Convert Keras model to TFF model\n",
    "    keras_model = tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32),\n",
    "        loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy']\n",
    "    )\n",
    "    return keras_model\n",
    "\n",
    "# Federated Averaging Process\n",
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Prepare Data for Federated Learning\n",
    "def create_federated_data(client_data, num_clients=5):\n",
    "    federated_data = []\n",
    "    client_data_split = np.array_split(client_data, num_clients)  # Split data into parts for clients\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        client_images, client_labels = client_data_split[i]\n",
    "        federated_data.append(\n",
    "            tff.simulation.ClientData(client_images, client_labels)\n",
    "        )\n",
    "    return federated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Perform Federated Learning for 10 Rounds\n",
    "def federated_learning_round(federated_data):\n",
    "    # Initialize the federated learning process\n",
    "    state = iterative_process.initialize()\n",
    "\n",
    "    for round_num in range(10):\n",
    "        print(f\"Round {round_num + 1}\")\n",
    "        state, metrics = iterative_process.next(state, federated_data)\n",
    "        print(f\"Metrics at round {round_num + 1}: {metrics}\")\n",
    "    \n",
    "    # Return the trained global model\n",
    "    return state.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save the Final Global Model after Federated Learning\n",
    "def save_model(model, model_filename='global_model.h5'):\n",
    "    model.save(model_filename)\n",
    "    print(f\"Global model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_from_csv_and_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAcer\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mphotos\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Folder containing the images\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_csv_and_images\u001b[49m(csv_file, image_folder)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Split the data into training and validation sets (80% train, 20% validation)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m train_images, val_images, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data_from_csv_and_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 8: Main function to load data, train local model, and simulate federated learning\n",
    "def main():\n",
    "    # Paths to your CSV file and image folder\n",
    "    csv_file = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\Labels.csv\"\n",
    "    image_folder = \"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\photos\"  # Folder containing the images\n",
    "    \n",
    "    # Load the data\n",
    "    images, labels = load_data_from_csv_and_images(csv_file, image_folder)\n",
    "    \n",
    "    # Split the data into training and validation sets (80% train, 20% validation)\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create the local model\n",
    "    num_classes = len(np.unique(labels))  # Number of unique classes\n",
    "    local_model = create_model(num_classes)\n",
    "    \n",
    "    # Train the model locally\n",
    "    history = train_local_model(train_images, train_labels, val_images, val_labels, local_model, epochs=10)\n",
    "    \n",
    "    # Save the trained local model\n",
    "    local_model.save('local_model.h5')\n",
    "    \n",
    "    # Prepare federated data for multiple clients (simulate real client data distribution)\n",
    "    federated_data = create_federated_data((train_images, train_labels), num_clients=5)\n",
    "    \n",
    "    # Perform federated learning for 10 rounds\n",
    "    global_model = federated_learning_round(federated_data)\n",
    "\n",
    "    # Save the final global model after federated learning\n",
    "    save_model(global_model)\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
