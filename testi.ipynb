{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "\n",
    "# 1. Load the trained model\n",
    "model = models.resnet101(pretrained=False)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\")) # Replace with your saved model path\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# 2. Prepare the test dataset and DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ensure the input size matches the model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=\"C:\\\\Users\\\\Acer\\\\Desktop\\\\Model\\\\test\", transform=test_transforms)  # Update with your test data path\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Perform testing and collect predictions\n",
    "all_preds = []  # Predicted class indices\n",
    "all_labels = []  # True class indices\n",
    "all_probs = []  # Probabilities for all classes\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)  # Move images to the device\n",
    "        labels = labels.to(device)  # Move labels to the device\n",
    "\n",
    "        outputs = model(images)  # Forward pass\n",
    "        probs = torch.softmax(outputs, dim=1)  # Compute probabilities for all classes\n",
    "        preds = torch.argmax(probs, dim=1)  # Get predicted class indices\n",
    "\n",
    "        all_probs.extend(probs.cpu().numpy())  # Move probabilities to CPU and convert to numpy\n",
    "        all_preds.extend(preds.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
    "        all_labels.extend(labels.cpu().numpy())  # Move true labels to CPU and convert to numpy\n",
    "\n",
    "# 4. Compute metrics\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Multi-class Precision, Recall, and F1-Score (macro-averaged)\n",
    "precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "print(f\"Precision (macro): {precision:.2f}\")\n",
    "print(f\"Recall (macro): {recall:.2f}\")\n",
    "print(f\"F1 Score (macro): {f1:.2f}\")\n",
    "\n",
    "# 5. Plot ROC Curve for each class\n",
    "n_classes = all_probs.shape[1]  # Number of classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Multi-Class Classification\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
